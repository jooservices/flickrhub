const fs = require('fs');
const path = require('path');
const crypto = require('crypto');
const amqp = require('amqplib');
const Redis = require('ioredis');
const { TokenStore } = require('../../packages/core/token-store');
const { JobStore } = require('../../packages/core/job-store');
const { FlickrClient } = require('../../packages/flickr-client');
const { MockFlickrClient } = require('../../packages/flickr-client/mock');
const { sendObservabilityLog } = require('../../packages/logger/observability');
const { config } = require('../../packages/config');

const safeStringify = (value) => {
  try {
    return JSON.stringify(value);
  } catch (err) {
    return '[unserializable]';
  }
};

const stableStringify = (value) => {
  const sorter = (obj) => {
    if (Array.isArray(obj)) return obj.map(sorter);
    if (obj && typeof obj === 'object') {
      return Object.keys(obj)
        .sort()
        .reduce((acc, key) => {
          acc[key] = sorter(obj[key]);
          return acc;
        }, {});
    }
    return obj;
  };
  return safeStringify(sorter(value));
};

const truncate = (str, max = 4000) => (str && str.length > max ? `${str.slice(0, max)}â€¦` : str);

const loadEnvFile = (filePath) => {
  if (!fs.existsSync(filePath)) return;
  const content = fs.readFileSync(filePath, 'utf8');
  content.split(/\r?\n/).forEach((line) => {
    const trimmed = line.trim();
    if (!trimmed || trimmed.startsWith('#')) return;
    const [key, ...rest] = trimmed.split('=');
    if (!key) return;
    const value = rest.join('=');
    if (!process.env[key]) process.env[key] = value;
  });
};

loadEnvFile(path.join(process.cwd(), '.env'));

const redisUrl = config.redisUrl;
const flickrKey = config.flickr.key;
const flickrSecret = config.flickr.secret;
const queueName = process.env.QUEUE_NAME || config.worker.queueName || 'flickr_rest';
const maxAttemptsDefault = config.jobs.retryAttempts;
const concurrencyDefault = config.worker.concurrency;
const mockFlickr = process.env.MOCK_FLICKR === 'true';
const queueConcurrency = (() => {
  if (queueName === 'flickr_rest' && config.worker.perQueue.rest) return config.worker.perQueue.rest;
  if (queueName === 'flickr_upload' && config.worker.perQueue.upload) return config.worker.perQueue.upload;
  if (queueName === 'flickr_replace' && config.worker.perQueue.replace) return config.worker.perQueue.replace;
  return concurrencyDefault;
})();
const cacheTtlSeconds = config.cache.ttlSeconds;
const cacheEnabled = config.cache.enabled;
const cachePrefix = config.cache.prefix;
const rabbitUrl = config.rabbitUrl;
const dlqName = 'flickr_dlq';
const callbackEnabled = config.jobs.callbackEnabled !== false;
const callbackRetryAttempts = config.jobs.callbackRetryAttempts;
const callbackRetryDelayMs = config.jobs.callbackRetryDelayMs;
const perSecondLimit = config.rateLimit.perSecond || 0;
const perSecondPrefix = config.rateLimit.perSecondPrefix || 'flickrhub:ratelimit:sec:';

if (!flickrKey || !flickrSecret) {
  await sendObservabilityLog({
    level: 'ERROR',
    kind: 'SYSTEM',
    event: 'worker_startup_error',
    message: 'Missing FLICKR_API_KEY/FLICKR_API_SECRET in environment',
    context: { queue: queueName },
    tags: ['worker', 'startup', 'error'],
  }).catch(() => {});
  process.exit(1);
}
if (!queueName) {
  await sendObservabilityLog({
    level: 'ERROR',
    kind: 'SYSTEM',
    event: 'worker_startup_error',
    message: 'Missing QUEUE_NAME in environment',
    tags: ['worker', 'startup', 'error'],
  }).catch(() => {});
  process.exit(1);
}

const tokenStore = new TokenStore();
const flickr = mockFlickr
  ? new MockFlickrClient({ apiKey: flickrKey, apiSecret: flickrSecret })
  : new FlickrClient({ apiKey: flickrKey, apiSecret: flickrSecret });
const redisClient = new Redis(redisUrl);
const jobStore = new JobStore({
  ttlCompleteDays: config.jobs.ttlCompleteDays,
  ttlFailDays: config.jobs.ttlFailDays,
});

const buildCacheKey = (method, params, userId) => {
  const payload = stableStringify({ method, params, userId });
  const hash = crypto.createHash('sha1').update(payload).digest('hex');
  return `${cachePrefix}${hash}`;
};

const getCached = async (key) => {
  if (!cacheEnabled) return null;
  const raw = await redisClient.get(key);
  if (!raw) return null;
  try {
    const parsed = JSON.parse(raw);
    const ttl = await redisClient.ttl(key);
    return { ...parsed, ttl };
  } catch (err) {
    return null;
  }
};

const setCached = async (key, value) => {
  if (!cacheEnabled) return;
  await redisClient.setex(key, cacheTtlSeconds, JSON.stringify(value));
};

const sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

const checkPerSecond = async (userId) => {
  if (!perSecondLimit || perSecondLimit <= 0) return { ok: true };
  const nowSec = Math.floor(Date.now() / 1000);
  const key = `${perSecondPrefix}${userId}:${nowSec}`;
  const count = await redisClient.incr(key);
  if (count === 1) {
    await redisClient.expire(key, 2); // short ttl per window
  }
  if (count > perSecondLimit) {
    return { ok: false, count };
  }
  return { ok: true, count };
};

const processor = async ({ method, params = {}, userId, jobId, attemptsMade, traceId }) => {
  const token = await tokenStore.getByUserId(userId);
  if (!token) {
    throw new Error(`Token not found for userId=${userId}`);
  }

  const { oauth_token: accessToken, oauth_token_secret: accessSecret } = token;
  if (!accessToken || !accessSecret) {
    throw new Error(`Invalid token shape for userId=${userId}`);
  }

  const cacheKey = buildCacheKey(method, params, userId);
  const cached = await getCached(cacheKey);
  if (cached) {
    await sendObservabilityLog({
      level: 'INFO',
      kind: 'SYSTEM',
      event: 'cache_hit',
      message: `${method} served from cache`,
      context: { user_id: userId, job_id: jobId, trace_id: traceId },
      payload: {
        flickr_method: method,
        params,
        cache_ttl_seconds: cached.ttl,
      },
      tags: ['cache', 'hit'],
    }).catch(() => {});
    
    const cacheResult = {
      from_cache: true,
      cache_ttl_seconds: cached.ttl,
      flickr: cached.data,
      observability: { ok: true, cached: true },
    };
    
    await sendObservabilityLog({
      level: 'INFO',
      kind: 'SYSTEM',
      event: 'flickr_api_call',
      message: `${method} succeeded (from cache)`,
      context: { user_id: userId, job_id: jobId, trace_id: traceId },
      payload: {
        flickr_method: method,
        params,
        response_code: 200,
        response_time_ms: 0,
        from_cache: true,
        cache_ttl_seconds: cached.ttl,
      },
      tags: ['flickr', 'api', 'cache'],
    }).catch(() => {});
    
    return cacheResult;
  }

    const start = Date.now();
  try {
    const result = await flickr.callRest(method, params, accessToken, accessSecret);
    const latency = Date.now() - start;
    await setCached(cacheKey, { data: result, cachedAt: Date.now() });
    const obsResult = await sendObservabilityLog({
      level: 'INFO',
      kind: 'SYSTEM',
      event: 'flickr_api_call',
      message: `${method} succeeded`,
      context: { user_id: userId, job_id: jobId, trace_id: traceId },
      payload: {
        flickr_method: method,
        params,
        response_code: 200,
        response_time_ms: latency,
        response_body: truncate(safeStringify(result), 4000),
      },
    });
    return { from_cache: false, flickr: result, observability: obsResult };
  } catch (error) {
    const latency = Date.now() - start;
    const currentAttempt = (attemptsMade || 0) + 1;
    const maxAttempts = maxAttemptsDefault;
    if (currentAttempt < maxAttempts) {
      await sendObservabilityLog({
        level: 'WARN',
        kind: 'SYSTEM',
        event: 'flickr_api_call_retry',
        message: `${method} retry attempt ${currentAttempt}/${maxAttempts}`,
        context: { user_id: userId, job_id: jobId, attempt: currentAttempt, max_attempts: maxAttempts, trace_id: traceId },
        payload: {
          flickr_method: method,
          params,
          response_code: error.status || error.code || null,
          response_time_ms: latency,
          response_body: truncate(error.body || error.message || '', 4000),
        },
        tags: ['flickr', 'api', 'retry'],
      });
    }
    const obsResult = await sendObservabilityLog({
      level: 'ERROR',
      kind: 'SYSTEM',
      event: 'flickr_api_call',
      message: `${method} failed: ${error.message}`,
      context: { user_id: userId, job_id: jobId, trace_id: traceId },
      payload: {
        flickr_method: method,
        params,
        response_code: error.status || error.code || null,
        response_time_ms: latency,
        response_body: truncate(error.body || error.message || '', 4000),
      },
      tags: ['flickr', 'api', 'error'],
    });
    error.observability = obsResult;
    
    // Persist final failure only if no more retries left
    if (currentAttempt >= maxAttempts && process.env.SAVE_FAILED_TO_MONGO !== 'false') {
      const payload = {
        state: 'failed',
        error: error.message,
        stacktrace: error.stack,
        observability: obsResult,
        method,
        params,
        userId,
        failedAt: new Date(),
        attempts_made: currentAttempt,
        max_attempts: maxAttempts,
      };
      await jobStore
        .save(jobId, payload)
        .then(() =>
          sendObservabilityLog({
            level: 'INFO',
            kind: 'SYSTEM',
            event: 'job_archived_mongo',
            message: `job ${jobId} archived to Mongo after failure`,
            context: { user_id: userId, job_id: jobId, queue: queueName },
            payload: { method, attempts_made: currentAttempt, max_attempts: maxAttempts },
            tags: ['job', 'dlq', 'mongo'],
          })
        )
        .catch((err) => console.warn('jobStore save failed:', err.message || err));
    }
    throw error;
  }
};

const sendCallback = async ({ callbackUrl, callbackSecret, body }) => {
  if (!callbackEnabled || !callbackUrl) return { sent: false, reason: 'disabled_or_missing' };
  const json = JSON.stringify(body);
  const headers = { 'Content-Type': 'application/json' };
  if (callbackSecret) {
    const sig = crypto.createHmac('sha256', callbackSecret).update(json).digest('hex');
    headers['X-Signature'] = sig;
  }
  
  const callbackStartTime = Date.now();
  
  for (let attempt = 1; attempt <= callbackRetryAttempts; attempt += 1) {
    try {
      const res = await fetch(callbackUrl, { method: 'POST', headers, body: json });
      const latency = Date.now() - callbackStartTime;
      if (res.ok) {
        // Debug log: Callback success
        debugLogger.logCallbackSuccess({
          jobId: body.job_id,
          userId: body.user_id,
          callbackUrl,
          httpStatus: res.status,
          attempts: attempt,
          latencyMs: latency,
          traceId: body.trace_id,
        });
        return { sent: true, status: res.status, attempts: attempt };
      }
      console.warn(`Callback POST status ${res.status} attempt ${attempt}/${callbackRetryAttempts}`);
    } catch (err) {
      console.warn(`Callback POST failed attempt ${attempt}/${callbackRetryAttempts}: ${err.message}`);
      if (attempt === callbackRetryAttempts) {
        // Debug log: Callback failure (exhausted)
        debugLogger.logCallbackFailure({
          jobId: body.job_id,
          userId: body.user_id,
          callbackUrl,
          error: err.message,
          attempts: attempt,
          maxAttempts: callbackRetryAttempts,
          traceId: body.trace_id,
        });
        return { sent: false, reason: err.message, attempts: attempt };
      }
    }
    if (attempt < callbackRetryAttempts) await sleep(callbackRetryDelayMs);
  }
  
  // Debug log: Callback failure (unknown)
  debugLogger.logCallbackFailure({
    jobId: body.job_id,
    userId: body.user_id,
    callbackUrl,
    error: 'unknown',
    attempts: callbackRetryAttempts,
    maxAttempts: callbackRetryAttempts,
    traceId: body.trace_id,
  });
  
  return { sent: false, reason: 'unknown', attempts: callbackRetryAttempts };
};

const start = async () => {
  const connection = await amqp.connect(rabbitUrl);
  const channel = await connection.createChannel();
  await channel.assertQueue(queueName, { durable: true, arguments: { 'x-queue-mode': 'lazy' } });
  await channel.assertQueue(dlqName, { durable: true, arguments: { 'x-queue-mode': 'lazy' } });
  channel.prefetch(queueConcurrency);

  await jobStore._ensureConnection();

  const handleMessage = async (msg) => {
    if (!msg) return;
    const content = msg.content.toString();
    let data;
    try {
      data = JSON.parse(content);
    } catch (err) {
      console.error('Invalid message payload, acking', err);
      await sendObservabilityLog({
        level: 'ERROR',
        kind: 'SYSTEM',
        event: 'queue_consume_error',
        message: 'Invalid message payload, acked',
        context: { queue: queueName },
        payload: { error: err.message },
        tags: ['queue', 'consume', 'error'],
      }).catch(() => {});
      channel.ack(msg);
      return;
    }
    const jobId = data.jobId || data.id;
    const attemptsMade = Number(msg.properties.headers?.attempts || 0);
    
    // Log received callbackUrl for debugging
    if (data.callbackUrl) {
      console.log(`[worker] Received job ${jobId} with callbackUrl=${data.callbackUrl.substring(0, 50)}...`);
    } else {
      console.log(`[worker] Received job ${jobId} without callbackUrl in message`);
    }
    
    try {
      const rateCheck = await checkPerSecond(data.userId);
      if (!rateCheck.ok) {
        // requeue after short delay to respect per-second pacing
        setTimeout(() => {
          channel.sendToQueue(queueName, Buffer.from(content), {
            persistent: true,
            headers: msg.properties.headers,
          });
        }, 1000);
        channel.ack(msg);
        return;
      }
      const result = await processor({ ...data, jobId, attemptsMade });
      await jobStore.updateJob(jobId, { state: 'completed', returnvalue: result, traceId: data.traceId });
      
      // Fallback: get callbackUrl from MongoDB if missing in message
      let resolvedCallbackUrl = data.callbackUrl;
      let resolvedCallbackSecret = data.callbackSecret;
      if (!resolvedCallbackUrl) {
        const jobDoc = await jobStore.get(jobId);
        if (jobDoc?.callbackUrl) {
          resolvedCallbackUrl = jobDoc.callbackUrl;
          resolvedCallbackSecret = jobDoc.callbackSecret || resolvedCallbackSecret;
          console.log(`[worker] Job ${jobId} callbackUrl restored from MongoDB: ${resolvedCallbackUrl.substring(0, 50)}...`);
        } else {
          console.log(`[worker] Job ${jobId} has no callbackUrl in message or MongoDB`);
        }
      }
      
      await sendObservabilityLog({
        level: 'INFO',
        kind: 'SYSTEM',
        event: 'job_completed',
        message: `job ${jobId} completed`,
        context: { user_id: data.userId, job_id: jobId, queue: queueName, trace_id: data.traceId },
        payload: { method: data.method, from_cache: result?.from_cache || false, attempts_made: attemptsMade },
        tags: ['job', 'completed'],
      });
      // Debug log: Callback start
      const callbackPayload = {
        job_id: jobId,
        user_id: data.userId,
        queue: queueName,
        state: 'completed',
        result: result?.flickr || result,
        error: null,
        from_cache: result?.from_cache || false,
        attempts_made: attemptsMade,
        max_attempts: maxAttemptsDefault,
        timestamp: new Date().toISOString(),
        trace_id: data.traceId,
      };
      
      debugLogger.logCallbackStart({
        jobId,
        userId: data.userId,
        callbackUrl: resolvedCallbackUrl,
        callbackSecret: resolvedCallbackSecret,
        state: 'completed',
        queue: queueName,
        traceId: data.traceId,
        payload: callbackPayload,
      });
      
      const cbResult = await sendCallback({
        callbackUrl: resolvedCallbackUrl,
        callbackSecret: resolvedCallbackSecret,
        body: callbackPayload,
      });
      if (cbResult?.sent) {
        await sendObservabilityLog({
          level: 'INFO',
          kind: 'SYSTEM',
          event: 'callback_success',
          message: `callback sent for job ${jobId}`,
          context: { user_id: data.userId, job_id: jobId, queue: queueName, trace_id: data.traceId },
          payload: { status: cbResult.status, attempts: cbResult.attempts || 1 },
          tags: ['callback', 'success'],
        });
      } else if (resolvedCallbackUrl) {
        await sendObservabilityLog({
          level: 'ERROR',
          kind: 'SYSTEM',
          event: 'callback_exhausted',
          message: `callback failed for job ${jobId}`,
          context: { user_id: data.userId, job_id: jobId, queue: queueName, trace_id: data.traceId },
          payload: { attempts: cbResult?.attempts || callbackRetryAttempts, reason: cbResult?.reason },
          tags: ['callback', 'failed', 'exhausted'],
        });
      }
      if (process.env.SAVE_COMPLETED_TO_MONGO === 'true') {
        await jobStore
          .save(jobId, {
            state: 'completed',
            returnvalue: result,
            method: data.method,
            params: data.params,
            userId: data.userId,
            completedAt: new Date(),
          })
          .then(() =>
            sendObservabilityLog({
              level: 'INFO',
              kind: 'SYSTEM',
              event: 'job_archived_mongo',
              message: `job ${jobId} archived to Mongo after completion`,
              context: { user_id: data.userId, job_id: jobId, queue: queueName },
              payload: { method: data.method },
              tags: ['job', 'completed', 'mongo'],
            })
          )
          .catch((err) => console.warn('jobStore save failed:', err.message || err));
      }
      channel.ack(msg);
    } catch (err) {
      const nextAttempt = attemptsMade + 1;
      if (nextAttempt < maxAttemptsDefault) {
        console.warn(`Retrying job ${jobId} attempt ${nextAttempt}/${maxAttemptsDefault}`);
        await jobStore.updateJob(jobId, { state: 'retrying', attempts: nextAttempt, failedReason: err.message });
        channel.ack(msg);
        channel.sendToQueue(queueName, Buffer.from(content), {
          persistent: true,
          headers: { attempts: nextAttempt },
        });
      } else {
        console.error(`Job ${jobId} moved to DLQ after ${nextAttempt} attempts: ${err.message}`);
        await jobStore.updateJob(jobId, {
          state: 'failed',
          failedReason: err.message,
          stacktrace: truncate(err.stack, 4000),
          failedAt: new Date(),
        });
        channel.ack(msg);
        channel.sendToQueue(dlqName, Buffer.from(content), {
          persistent: true,
          headers: { attempts: nextAttempt, failed: true },
        });
        await sendObservabilityLog({
          level: 'ERROR',
          kind: 'SYSTEM',
          event: 'job_dlq',
          message: `job ${jobId} moved to DLQ`,
          context: { user_id: data.userId, job_id: jobId, queue: queueName, trace_id: data.traceId },
          payload: { method: data.method, attempts_made: nextAttempt, error: err.message },
          tags: ['job', 'dlq'],
        });
        
        // Fallback: get callbackUrl from MongoDB if missing in message
        let failedCallbackUrl = data.callbackUrl;
        let failedCallbackSecret = data.callbackSecret;
        if (!failedCallbackUrl) {
          const jobDoc = await jobStore.get(jobId);
          if (jobDoc?.callbackUrl) {
            failedCallbackUrl = jobDoc.callbackUrl;
            failedCallbackSecret = jobDoc.callbackSecret || failedCallbackSecret;
            console.log(`[worker] Job ${jobId} callbackUrl restored from MongoDB for failed job: ${failedCallbackUrl.substring(0, 50)}...`);
          } else {
            console.log(`[worker] Job ${jobId} has no callbackUrl in message or MongoDB for failed job`);
          }
        }
        
        const failedCallbackPayload = {
          job_id: jobId,
          user_id: data.userId,
          queue: queueName,
          state: 'failed',
          result: null,
          error: { message: err.message, code: null },
          from_cache: false,
          attempts_made: nextAttempt,
          max_attempts: maxAttemptsDefault,
          timestamp: new Date().toISOString(),
          trace_id: data.traceId,
        };
        
        // Debug log: Callback start for failed job
        debugLogger.logCallbackStart({
          jobId,
          userId: data.userId,
          callbackUrl: failedCallbackUrl,
          callbackSecret: failedCallbackSecret,
          state: 'failed',
          queue: queueName,
          traceId: data.traceId,
          payload: failedCallbackPayload,
        });
        
        const cbResult = await sendCallback({
          callbackUrl: failedCallbackUrl,
          callbackSecret: failedCallbackSecret,
          body: failedCallbackPayload,
        });
        if (cbResult?.sent) {
          await sendObservabilityLog({
            level: 'INFO',
            kind: 'SYSTEM',
            event: 'callback_success',
            message: `callback sent for job ${jobId}`,
            context: { user_id: data.userId, job_id: jobId, queue: queueName, trace_id: data.traceId },
            payload: { status: cbResult.status, attempts: cbResult.attempts || 1 },
            tags: ['callback', 'success'],
          });
        } else if (failedCallbackUrl) {
          await sendObservabilityLog({
            level: 'ERROR',
            kind: 'SYSTEM',
            event: 'callback_exhausted',
            message: `callback failed for job ${jobId}`,
            context: { user_id: data.userId, job_id: jobId, queue: queueName, trace_id: data.traceId },
            payload: { attempts: cbResult?.attempts || callbackRetryAttempts, reason: cbResult?.reason },
            tags: ['callback', 'failed', 'exhausted'],
          });
        }
      }
    }
  };

  await sendObservabilityLog({
    level: 'INFO',
    kind: 'SYSTEM',
    event: 'worker_started',
    message: `Worker started for ${queueName} concurrency=${queueConcurrency}`,
    context: { queue: queueName, concurrency: queueConcurrency },
  });

  channel.consume(queueName, handleMessage, { noAck: false });

  const shutdown = async () => {
    try {
      await redisClient.quit();
      await jobStore.close();
      await channel.close();
      await connection.close();
      await sendObservabilityLog({
        level: 'INFO',
        kind: 'SYSTEM',
        event: 'worker_shutdown',
        message: `Worker shutting down for ${queueName}`,
        context: { queue: queueName },
        tags: ['worker', 'shutdown'],
      }).catch(() => {});
      process.exit(0);
    } catch (err) {
      console.error('Graceful shutdown failed', err);
      process.exit(1);
    }
  };
  process.on('SIGINT', shutdown);
  process.on('SIGTERM', shutdown);
};

start().catch((err) => {
  console.error('Worker failed to start', err);
  process.exit(1);
});
